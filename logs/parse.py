def filter_log_file(input_file, output_file):
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞, —É–¥–∞–ª—è—è —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤.
    
    Args:
        input_file (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
        output_file (str): –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    
    # –°–ø–∏—Å–æ–∫ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
    prefixes_to_remove = [
        "{'loss':",
        "{'eval_loss':", 
        "{'train_runtime':",
        "  active_adapters",
        "New chosen layers:",
        "self.lora_ranks:",
        "We will use the GPU:",
        "model is",
        "trainable params",
        "[H[JWe",
        "        ",
    ]
    
    try:
        with open(input_file, 'r', encoding='utf-8') as infile:
            with open(output_file, 'w', encoding='utf-8') as outfile:
                for line in infile:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å –ª—é–±–æ–≥–æ –∏–∑ –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤
                    if not any(line.startswith(prefix) for prefix in prefixes_to_remove):
                        outfile.write(line)
        
        print(f"–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω!")
        print(f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª: {input_file}")
        print(f"–†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π —Ñ–∞–π–ª: {output_file}")
        
    except FileNotFoundError:
        print(f"–û—à–∏–±–∫–∞: –§–∞–π–ª '{input_file}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    except Exception as e:
        print(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    input_filename = "paper_exp_20092025.txt"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –ø—É—Ç—å –∫ –≤–∞—à–µ–º—É —Ñ–∞–π–ª—É
    output_filename = "paper_exp_20092025_parsed.txt"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –∂–µ–ª–∞–µ–º–æ–µ –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    
    filter_log_file(input_filename, output_filename)